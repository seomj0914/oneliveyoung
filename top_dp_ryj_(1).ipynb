{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XSEKIkmY129"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXcCpxyPY12-"
      },
      "source": [
        "#### 탑리뷰어 df\n",
        "\n",
        "작성자, 주문 날짜, 리뷰 작성 날짜, 리뷰 내용, 리뷰당 ‘도움이 돼요’ 개수, 한달 이상 사용, 재구매 여부, 사진 개수, 제품 구매 방법, 리뷰 고유번호, 평점(긍부정)\n",
        "리뷰 쓴 주기, 리뷰 길이, 총 ‘도움이 돼요’, 리뷰당 ‘도움이 돼요’ (평균), 체험단 리뷰와 일반 리뷰 차이 (리뷰 길이 편차)\n",
        "\n",
        "- gdasSeq  :  리뷰 고유번호\n",
        "- gdasScrVal: 평점 (2,4,6,8,10)\n",
        "- dispRegDate : 리뷰 업로드 날짜\n",
        "- gdasCont : 리뷰 본문\n",
        "- ordDate: 상품 주문 날짜\n",
        "- photoList: 사진 리스트 (사진 없으면 null)\n",
        "- recommCnt: 도움이 돼요 개수\n",
        "- renewUsed1mmGdasYn: 한달이상 사용\n",
        "- firstGdasYn: 첫 구매 여부 (재구매면 “N” 아니면 “Y”)\n",
        "- mbrNo: 리뷰를 작성한 회원의 고유 식별자\n",
        "- gdasSctCd : 제품 구매 방법 (10 - 온라인, 60 - 매장, 50 - 체험단, 70 - 선물)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo4TiN7IY12_",
        "outputId": "fbf09601-ae6b-4f92-8881-dc9ed5b3de6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/mn/w592whfs2tb4g8s658288fb00000gn/T/ipykernel_9186/3744978623.py:3: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  top_df = pd.read_csv(topReviews_path, header=0, encoding='UTF-8')\n"
          ]
        }
      ],
      "source": [
        "# 탑리뷰어 정보 DF로 가져오기\n",
        "topReviews_path = '/Users/ryeongjoo/Desktop/workspace/semi_prj/topReviews.csv'\n",
        "top_df = pd.read_csv(topReviews_path, header=0, encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mids7AYdY12_"
      },
      "outputs": [],
      "source": [
        "# 필요한 칼럼만 담은 DF\n",
        "my_top_df = top_df[['mbrNo','ordDate','dispRegDate','gdasCont','recommCnt','renewUsed1mmGdasYn','firstGdasYn', 'gdasSeq', 'gdasScrVal','gdasSctCd' ]]\n",
        "# print(my_top_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRtJ0VnNY13A"
      },
      "outputs": [],
      "source": [
        "# NaN 값 드랍\n",
        "my_top_df = my_top_df.dropna(subset=['gdasCont'])\n",
        "\n",
        "# 영어 소문자 통일\n",
        "my_top_df['gdasCont'] = my_top_df['gdasCont'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuadh85EY13A"
      },
      "outputs": [],
      "source": [
        "# 정규식을 이용하여 이모티콘 추출하는 함수\n",
        "def extract_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001f600-\\U0001f64f\"  # 이모티콘\n",
        "        u\"\\U0001f300-\\U0001f5ff\"  # 기호 및 문장 부호\n",
        "        u\"\\U0001f680-\\U0001f6ff\"  # 기타 이모티콘\n",
        "        u\"\\U0001f1e0-\\U0001f1ff\"  # 국기 및 기호\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.findall(text)\n",
        "\n",
        "# '이모티콘' 열 생성\n",
        "my_top_df['unicode'] = my_top_df['gdasCont'].apply(lambda x: extract_emoji(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSBLz1iSY13A"
      },
      "outputs": [],
      "source": [
        "# 리뷰내용 중복문자, 이모티콘 제거\n",
        "clean_reviews = []\n",
        "emoticon_list = []\n",
        "\n",
        "def remove_emoji(text):\n",
        "    # 이모티콘 패턴 정의\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # 이모티콘\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # 심볼\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # 트랜스포트 및 지도\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # 국기 및 이모지\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    # 이모티콘 제거\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "for review in my_top_df['gdasCont'] :\n",
        "    \n",
        "    # 초성, 줄바꿈 제거\n",
        "    review = re.sub('[ㄱ-ㅎㅏ-ㅣ]', '', review)\n",
        "    review = re.sub('[\\r\\n]', ' ', review)  \n",
        "    \n",
        "    # 이모티콘 제거\n",
        "    review = remove_emoji(review)\n",
        "    \n",
        "    clean_reviews.append(review)\n",
        "    \n",
        "my_top_df['gdasCont'] = clean_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4OWHHWxY13A"
      },
      "outputs": [],
      "source": [
        "# 리뷰 길이 칼럼 추가\n",
        "my_top_df['cont_length'] = my_top_df['gdasCont'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# print(my_top_df.head())\n",
        "\n",
        "# 이모티콘 개수 칼럼 추가\n",
        "my_top_df['emoCnt'] = my_top_df['unicode'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KotjTvQMY13A"
      },
      "outputs": [],
      "source": [
        "# 리뷰 주기 칼럼\n",
        "# 리뷰 작성 날짜 - 구매일자\n",
        "\n",
        "# 날짜형으로 변환\n",
        "my_top_df['dispRegDate'] = pd.to_datetime(my_top_df['dispRegDate'])\n",
        "my_top_df['ordDate'] = pd.to_datetime(my_top_df['ordDate'])\n",
        "\n",
        "# NaN이 아닌 행 선택\n",
        "subset = my_top_df[my_top_df['ordDate'].notnull() ]\n",
        "\n",
        "# 두 날짜의 차이를 계산하여 새로운 칼럼에 추가\n",
        "my_top_df.loc[subset.index, 'or_diff'] = my_top_df['dispRegDate'] - my_top_df['ordDate']\n",
        "\n",
        "# 결과 출력\n",
        "# print(my_top_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz6kRwZoY13A"
      },
      "outputs": [],
      "source": [
        "my_top_df['pn'] = [1 if x > 6 else 0 for x in my_top_df['gdasScrVal']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WC7MYAiY13A"
      },
      "source": [
        "#### 리뷰어별 df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb9mYLfzY13B"
      },
      "outputs": [],
      "source": [
        "reviewer_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7UHZqxxY13B"
      },
      "outputs": [],
      "source": [
        "# mbrNo 칼럼 생성\n",
        "unique_mbrNo = my_top_df['mbrNo'].unique()  # 중복을 제거한 mbrNo 값 추출\n",
        "reviewer_df['mbrNo'] = pd.Series(unique_mbrNo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YdeS5lmY13B"
      },
      "outputs": [],
      "source": [
        "# 리뷰어별 평균 리뷰 길이\n",
        "# 총 리뷰 길이 평균 계산\n",
        "contlen_df = my_top_df.groupby('mbrNo')['cont_length'].mean().reset_index().rename(columns={'cont_length': 'contlen_mean'})\n",
        "\n",
        "# reviewer_df와 contlen_df 조인\n",
        "reviewer_df = pd.merge(reviewer_df, contlen_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHf0wtLTY13B"
      },
      "outputs": [],
      "source": [
        "# 리뷰어별 총 도움이 돼요 개수\n",
        "\n",
        "# 총 리뷰 개수 계산\n",
        "recommSum_df = my_top_df.groupby('mbrNo')['recommCnt'].sum().reset_index().rename(columns={'recommCnt': 'total_recomm'})\n",
        "\n",
        "# reviewer_df와 recommSum_df 조인\n",
        "reviewer_df = pd.merge(reviewer_df, recommSum_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm87xD-zY13B"
      },
      "outputs": [],
      "source": [
        "# 리뷰어별 작성 리뷰 개수\n",
        "reviewCnt_df = my_top_df.groupby('mbrNo')['gdasCont'].count().reset_index().rename(columns={'gdasCont': 'gdas_cnt'})\n",
        "reviewer_df = pd.merge(reviewer_df, reviewCnt_df, on='mbrNo', how='left')\n",
        "\n",
        "# 리뷰어별 리뷰 개수당 평균 도움이 돼요 개수\n",
        "reviewer_df['recomm_mean'] = reviewer_df['total_recomm'] / reviewer_df['gdas_cnt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRIQsPeDY13B"
      },
      "outputs": [],
      "source": [
        "# 리뷰어별 체험단 리뷰와 일반 리뷰 차이 (리뷰 길이 편차)\n",
        "\n",
        "# 체험단 리뷰길이 평균\n",
        "test_df = my_top_df.loc[my_top_df['gdasSctCd'] == 50].groupby('mbrNo')['cont_length'].mean()\n",
        "\n",
        "# 체험단 제외한 리뷰 길이 평균\n",
        "buy_df = my_top_df.loc[my_top_df['gdasSctCd'] != 50].groupby('mbrNo')['cont_length'].mean()\n",
        "\n",
        "# 체험단 리뷰길이 - 체험단 제외한 리뷰 길이 \n",
        "diff_df = pd.DataFrame({'tb_len_diff': test_df - buy_df}).reset_index()\n",
        "\n",
        "# reviewer_df와 recommSum_df 조인\n",
        "reviewer_df = pd.merge(reviewer_df, diff_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtSgOzFZY13C"
      },
      "outputs": [],
      "source": [
        "# 평균 이모티콘 개수\n",
        "emoCntMean_df = my_top_df.groupby('mbrNo')['emoCnt'].mean().reset_index().rename(columns={'emoCnt': 'emoCntMean'})\n",
        "reviewer_df = pd.merge(reviewer_df, emoCntMean_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXY0gCqIY13C"
      },
      "outputs": [],
      "source": [
        "# 평점 긍부정 경향\n",
        "scrPN_df = my_top_df.groupby('mbrNo')['pn'].mean().reset_index().rename(columns={'pn': 'scrPN'})\n",
        "reviewer_df = pd.merge(reviewer_df, scrPN_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhIK1Y7zY13C",
        "outputId": "a1331360-5e4e-4217-8329-905824b80862"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mbrNo</th>\n",
              "      <th>contlen_mean</th>\n",
              "      <th>total_recomm</th>\n",
              "      <th>gdas_cnt</th>\n",
              "      <th>recomm_mean</th>\n",
              "      <th>tb_len_diff</th>\n",
              "      <th>emoCntMean</th>\n",
              "      <th>topRvrRnk</th>\n",
              "      <th>topRvrRnk_group</th>\n",
              "      <th>scrPN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M0000004535694</td>\n",
              "      <td>83.013333</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>300</td>\n",
              "      <td>3.393333</td>\n",
              "      <td>218.630508</td>\n",
              "      <td>0.343333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M0000012163234</td>\n",
              "      <td>101.200000</td>\n",
              "      <td>1216.0</td>\n",
              "      <td>80</td>\n",
              "      <td>15.200000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M0000016082816</td>\n",
              "      <td>110.190909</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>110</td>\n",
              "      <td>10.700000</td>\n",
              "      <td>222.396226</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.945455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M0000003453847</td>\n",
              "      <td>73.930000</td>\n",
              "      <td>604.0</td>\n",
              "      <td>100</td>\n",
              "      <td>6.040000</td>\n",
              "      <td>248.250000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M0000010425691</td>\n",
              "      <td>505.030000</td>\n",
              "      <td>765.0</td>\n",
              "      <td>100</td>\n",
              "      <td>7.650000</td>\n",
              "      <td>37.208333</td>\n",
              "      <td>1.560000</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            mbrNo  contlen_mean  total_recomm  gdas_cnt  recomm_mean  \\\n",
              "0  M0000004535694     83.013333        1018.0       300     3.393333   \n",
              "1  M0000012163234    101.200000        1216.0        80    15.200000   \n",
              "2  M0000016082816    110.190909        1177.0       110    10.700000   \n",
              "3  M0000003453847     73.930000         604.0       100     6.040000   \n",
              "4  M0000010425691    505.030000         765.0       100     7.650000   \n",
              "\n",
              "   tb_len_diff  emoCntMean  topRvrRnk topRvrRnk_group     scrPN  \n",
              "0   218.630508    0.343333          1               1  1.000000  \n",
              "1   304.000000    0.250000          2               1  0.850000  \n",
              "2   222.396226    0.009091          3               1  0.945455  \n",
              "3   248.250000    0.450000          4               1  0.990000  \n",
              "4    37.208333    1.560000          5               1  0.960000  "
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviewer_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kqD4NKDY13C"
      },
      "source": [
        "#### 상,중,하위 리뷰어 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWj6IyDLY13C",
        "outputId": "27e76c0f-8169-4f6e-eaf5-594d58aa6b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-27.177575757575752\n",
            "83.01333333333334 101.2 110.19090909090909\n"
          ]
        }
      ],
      "source": [
        "# 탑리뷰어(1~1000) 상위,중위,하위로 나눠서 리뷰길이차이 (편차) 구하기\n",
        "\n",
        "reviewer_df['topRvrRnk'] = reviewer_df['mbrNo'].index+1\n",
        "\n",
        "#탑리뷰어(1~2000) 상위,중위,하위로 나눈 칼럼 추가\n",
        "reviewer_df['topRvrRnk_group'] = pd.cut(reviewer_df['topRvrRnk'], bins=[0, 657, 1315, 1972], labels=[1, 2, 3])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7h2_zolY13C",
        "outputId": "83f535b1-7776-4afa-fa28-7b16d8350ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "190.0\n",
            "300.0 80.0 110.0\n"
          ]
        }
      ],
      "source": [
        "# 상위 리뷰어와 하위 리뷰어 평균 작성 리뷰 개수 차이 \n",
        "high_review_cnt = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['gdas_cnt'].mean()\n",
        "middle_review_cnt = reviewer_df.loc[reviewer_df['topRvrRnk'] == 2]['gdas_cnt'].mean()\n",
        "low_review_cnt = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['gdas_cnt'].mean()\n",
        "\n",
        "diff_review_cnt = high_review_cnt - low_review_cnt\n",
        "print(diff_review_cnt)\n",
        "print(high_review_cnt, middle_review_cnt, low_review_cnt)\n",
        "\n",
        "# 상위 리뷰어들의 평균 리뷰 개수가 훨씬 많음을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XkoCro4Y13C"
      },
      "outputs": [],
      "source": [
        "#상위 리뷰어와 하위 리뷰어 차이 (리뷰 길이 편차)\n",
        "high_review_length = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['contlen_mean'].mean()\n",
        "middle_review_length = reviewer_df.loc[reviewer_df['topRvrRnk'] == 2]['contlen_mean'].mean()\n",
        "low_review_length = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['contlen_mean'].mean()\n",
        "\n",
        "diff_review_length = high_review_length - low_review_length\n",
        "print(diff_review_length)\n",
        "print(high_review_length, middle_review_length, low_review_length)\n",
        "\n",
        "# 오히려 하위 탑리뷰어들의 평균 리뷰 길이가 더 길다는 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHoPXgR-Y13D",
        "outputId": "602c8781-7f59-47b3-f2b6-a8d13f1cce09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.33424242424242423\n"
          ]
        }
      ],
      "source": [
        "#상위 리뷰어와 하위 리뷰어 이모티콘 개수 차이\n",
        "high_review_emo = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['emoCntMean'].mean()\n",
        "low_review_emo = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['emoCntMean'].mean()\n",
        "\n",
        "diff_review_emo = high_review_emo - low_review_emo\n",
        "print(diff_review_emo)\n",
        "\n",
        "# 상위 탑리뷰어들의 평균 이모티콘 개수가 더 많다는 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqshe7xkY13D",
        "outputId": "a614b52d-e92a-447f-c95a-a4583b5d5646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.054545454545454564\n"
          ]
        }
      ],
      "source": [
        "# 상위 리뷰어와 하위 리뷰어 평점 긍부정 차이 \n",
        "high_review_pn = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['scrPN'].mean()\n",
        "low_review_pn = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['scrPN'].mean()\n",
        "\n",
        "diff_review_pn = high_review_pn - low_review_pn\n",
        "print(diff_review_pn)\n",
        "\n",
        "# 상위 탑리뷰어들이 평균적으로 더 높은 평점을 주었다는 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g2fOmrLY13D",
        "outputId": "79ffa49c-b968-4b7f-d3a5-659e80b41dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-7.306666666666666\n",
            "3.3933333333333335 15.2 10.7\n"
          ]
        }
      ],
      "source": [
        "# 상위 리뷰어와 하위 리뷰어 평균 도움이돼요 차이 \n",
        "high_review_rcm = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['recomm_mean'].mean()\n",
        "middle_review_rcm = reviewer_df.loc[reviewer_df['topRvrRnk'] == 2]['recomm_mean'].mean()\n",
        "low_review_rcm = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['recomm_mean'].mean()\n",
        "\n",
        "diff_review_rcm = high_review_rcm - low_review_rcm\n",
        "print(diff_review_rcm)\n",
        "print(high_review_rcm, middle_review_rcm, low_review_rcm)\n",
        "\n",
        "# 하위 리뷰어들의 평균 도움이돼요 개수가 더 많다는 것을 알 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O81g3z-aY13D"
      },
      "outputs": [],
      "source": [
        "# def text_len(text):\n",
        "#     return re.sub('[^ㅏ-ㅣ가-힣 .,+…\\';:\\-ㆍ\\(\\)&0-9A-Za-z]+', '', text)\n",
        "# my_top_df['gdasCont'][:10].apply(text_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlZad26RY13D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wsbfXyuY13D"
      },
      "source": [
        "#### 리뷰 내용 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxfRnWybY13D",
        "outputId": "1b9e7575-5d13-4587-a451-30edfc5e6ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['제', '최근', '올리브영', '가장', '많이', '구매', '했던', '제품', '중', '하나', '입니다', '신랑', '30', 'g', '짜', '리', '하루', '두', '봉지', '씩', '먹네요', '하지만', '제입', '많이', '달아요'], ['허브', '쏠트', '믹스넛', '견과류', '구성은', '맘', '드는데', '넘', '짜요', '그래도', '1', '1', '행사', '하길래', '구매', '했는데', '겉', '묻은', '가루', '털어내고', '먹어야', '해'], ['아침', '주로', '마시고', '있는', '사과', '당근', '맛', '이', '너', '주스', '입니다', '제', '5년', '을', '넘게', '마시고', '있는데', '꾸준하게', '마시면', '화장실', '가는게', '편해져서', '좋아요'], ['신랑', '줄려고', '신청', '했어요', '다비도프', '향수', '프랑스', '만들어', '졌고', '향수병', '네모', '형태', '되어있고', '잡기', '편하네요', '제품', '받고', '바로', '신랑', '뿌려', '봤는데', '향', '딱', '남자', '들', '좋아할만', '한', '향', '요', '일단', '향', '중요하지만', '지속', '력', '좋아야', '해서', '신랑', '뿌리', '한두', '시간', '지나서도', '향', '나는지', '옆', '가봤더니', '진하게는', '아니지만', '은은하게', '잔향', '남아', '있는듯', '하네요', '날씨', '점점', '더워지는데', '여름', '뿌려도', '좋을것', '같다는', '생각', '드네', '나이', '상관없이', '모든', '연령', '층', '사용', '하기에', '괜찮은', '제품', '듯', '합니다'], ['팽이버섯', '유산균', '발효', '액', '들어가서', '꾸준하게', '마시면', '화장실', '가는게', '편해지네요']]\n"
          ]
        }
      ],
      "source": [
        "# 토큰화\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "tokens_results = []\n",
        "\n",
        "for text in my_top_df['gdasCont'].head(5):\n",
        "    \n",
        "    # Okt 객체 생성\n",
        "    okt = Okt()\n",
        "\n",
        "    # 초성, 줄바꿈 제거\n",
        "    text = re.sub('[ㄱ-ㅎㅏ-ㅣ\\r\\n]', '', text)\n",
        "\n",
        "    tokens = okt.pos(text)\n",
        "    result = []\n",
        "\n",
        "    for word, tag in tokens:\n",
        "        if tag not in ['Josa', 'Eomi', 'Punctuation']:\n",
        "            result.append(word)\n",
        "\n",
        "    tokens_results.append(result)\n",
        "    \n",
        "print(tokens_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZKepz33Y13D",
        "outputId": "64c95f1a-c614-496e-849c-b2eb19919bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['30' '가장' '구매' '달아요' '많이' '먹네요' '봉지' '신랑' '올리브영' '입니다' '제입' '제품' '최근'\n",
            " '하나' '하루' '하지만' '했던']\n",
            "['가루' '견과류' '구매' '구성은' '그래도' '드는데' '먹어야' '묻은' '믹스넛' '쏠트' '짜요' '털어내고' '하길래'\n",
            " '했는데' '행사' '허브']\n",
            "['5년' '가는게' '꾸준하게' '넘게' '당근' '마시고' '마시면' '사과' '아침' '입니다' '있는' '있는데' '좋아요'\n",
            " '주로' '주스' '편해져서' '화장실']\n",
            "['가봤더니' '같다는' '괜찮은' '나는지' '나이' '날씨' '남아' '남자' '네모' '다비도프' '더워지는데' '되어있고'\n",
            " '드네' '만들어' '모든' '바로' '받고' '봤는데' '뿌려' '뿌려도' '뿌리' '사용' '상관없이' '생각' '시간'\n",
            " '신랑' '신청' '아니지만' '여름' '연령' '은은하게' '일단' '있는듯' '잔향' '잡기' '점점' '제품' '졌고'\n",
            " '좋아야' '좋아할만' '좋을것' '줄려고' '중요하지만' '지나서도' '지속' '진하게는' '편하네요' '프랑스' '하기에'\n",
            " '하네요' '한두' '합니다' '해서' '했어요' '향수' '향수병' '형태']\n",
            "['가는게' '꾸준하게' '들어가서' '마시면' '발효' '유산균' '팽이버섯' '편해지네요' '화장실']\n"
          ]
        }
      ],
      "source": [
        "# 키워드 추출\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "for documents in tokens_results:\n",
        "\n",
        "    # TfidfVectorizer 객체 생성\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # TfidfVectorizer로 문서 벡터화 수행\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "    # get_feature_names() 메서드를 이용해 단어 목록과 각 단어의 인덱스 확인\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjnhCHjpY13E",
        "outputId": "2e12770e-6bc6-4eb3-c1f8-ce9414f4a16d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Kss]: Oh! You have konlpy.tag.Mecab in your environment. Kss will take this as a backend! :D\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "하지만 제입엔 많이 달아요 신랑이 30g짜리를 하루에 두봉지씩  먹네요 제가 최근에 올리브영에서 가장 많이  구매를 했던 제품중 하나입니다\n",
            "그래도 1+1 행사를 하길래 구매를  했는데 겉에 묻은 가루를 털어내고  먹어야 해요 허브쏠트 믹스넛은 견과류구성은  맘에 드는데 넘짜요\n",
            "제가 5년을 넘게 마시고 있는데 꾸준하게  마시면 화장실 가는게 편해져서 좋아요 아침에 주로 마시고 있는 사과당근맛  이너주스입니다\n",
            "신랑을 줄려고 신청을 했어요~ 일단 향도 중요하지만 지속력도 좋아야  해서 신랑이 뿌리고 한두시간 지나서도  향이 나는지 옆에 가봤더니 진하게는  아니지만 은은하게 잔향이 남아 있는듯  하네요 나이와 상관없이 모든 연령층이 사용하기에  괜찮은 제품인듯 합니다\n",
            "팽이버섯 유산균 발효액이 들어가서  꾸준하게 마시면 화장실 가는게  편해지네요\n"
          ]
        }
      ],
      "source": [
        "# 요약\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Komoran\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import kss\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "for document in my_top_df['gdasCont'].head(5):\n",
        "    # Okt 객체 생성\n",
        "    okt = Okt()\n",
        "\n",
        "    # 문장 단위로 분리\n",
        "    sentences = kss.split_sentences(document)\n",
        "\n",
        "    # 각 문장에서 명사, 형용사, 동사만 추출하여 리스트에 저장\n",
        "    words_list = []\n",
        "    for sentence in sentences:\n",
        "        words = okt.pos(sentence, stem=True)\n",
        "        words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "        words_list.append(' '.join(words))\n",
        "\n",
        "    # TF-IDF를 계산하여 문장 간 유사도를 계산\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform(words_list)\n",
        "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "    # TextRank 알고리즘을 적용하여 문서 요약\n",
        "    def summarize(document, num_sentences=3):\n",
        "\n",
        "\n",
        "        # 각 문장에서 명사, 형용사, 동사만 추출하여 리스트에 저장\n",
        "        words_list = []\n",
        "        for sentence in sentences:\n",
        "            words = okt.pos(sentence, stem=True)\n",
        "            words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "            words_list.append(' '.join(words))\n",
        "\n",
        "        # TF-IDF를 계산하여 문장 간 유사도를 계산\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf = vectorizer.fit_transform(words_list)\n",
        "        similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "        # TextRank 알고리즘을 적용하여 문서 요약\n",
        "        similarity_graph = similarity_matrix\n",
        "        nx_graph = nx.from_numpy_array(similarity_graph)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "\n",
        "        # 핵심 문장 추출\n",
        "        ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
        "        selected_sentences = [sentences[index] for _, index in ranked_sentences[:num_sentences]]\n",
        "        return ' '.join(selected_sentences)\n",
        "\n",
        "    # 문서 요약\n",
        "    summary = summarize(document, num_sentences=3)\n",
        "    print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPWc4_o9Y13E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g85FFJcXY13E",
        "outputId": "d54a8922-8bfd-4c4a-c466-bdfb14bd6a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "하지만 제입엔 많이 달아요 신랑이 30g짜리를 하루에 두봉지씩  먹네요 제가 최근에 올리브영에서 가장 많이  구매를 했던 제품중 하나입니다\n",
            "그래도 1+1 행사를 하길래 구매를  했는데 겉에 묻은 가루를 털어내고  먹어야 해요 허브쏠트 믹스넛은 견과류구성은  맘에 드는데 넘짜요\n",
            "제가 5년을 넘게 마시고 있는데 꾸준하게  마시면 화장실 가는게 편해져서 좋아요 아침에 주로 마시고 있는 사과당근맛  이너주스입니다\n",
            "신랑을 줄려고 신청을 했어요~ 일단 향도 중요하지만 지속력도 좋아야  해서 신랑이 뿌리고 한두시간 지나서도  향이 나는지 옆에 가봤더니 진하게는  아니지만 은은하게 잔향이 남아 있는듯  하네요 나이와 상관없이 모든 연령층이 사용하기에  괜찮은 제품인듯 합니다\n",
            "팽이버섯 유산균 발효액이 들어가서  꾸준하게 마시면 화장실 가는게  편해지네요\n"
          ]
        }
      ],
      "source": [
        "# 요약2\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Komoran\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import kss\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "for document in my_top_df['gdasCont'].head(5):\n",
        "    # Okt 객체 생성\n",
        "    okt = Okt()\n",
        "    \n",
        "    # 초성, 줄바꿈 제거\n",
        "    document = re.sub('[ㄱ-ㅎㅏ-ㅣ]', '', document)\n",
        "    document = re.sub('[\\r\\n]', ' ', document)\n",
        "    \n",
        "    # 문장 단위로 분리\n",
        "    sentences = kss.split_sentences(document)\n",
        "    \n",
        "    # 각 문장에서 명사, 형용사, 동사만 추출하여 리스트에 저장\n",
        "    words_list = []\n",
        "    for sentence in sentences:\n",
        "        words = okt.pos(sentence, stem=True)\n",
        "        words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "        words_list.append(' '.join(words))\n",
        "\n",
        "    # TF-IDF를 계산하여 문장 간 유사도를 계산\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform(words_list)\n",
        "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "    # TextRank 알고리즘을 적용하여 문서 요약\n",
        "    def summarize(document, num_sentences=3):\n",
        "\n",
        "\n",
        "        # 각 문장에서 명사, 형용사, 동사만 추출하여 리스트에 저장\n",
        "        words_list = []\n",
        "        for sentence in sentences:\n",
        "            words = okt.pos(sentence, stem=True)\n",
        "            words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "            words_list.append(' '.join(words))\n",
        "\n",
        "        # TF-IDF를 계산하여 문장 간 유사도를 계산\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf = vectorizer.fit_transform(words_list)\n",
        "        similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "        # TextRank 알고리즘을 적용하여 문서 요약\n",
        "        similarity_graph = similarity_matrix\n",
        "        nx_graph = nx.from_numpy_array(similarity_graph)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "\n",
        "        # 핵심 문장 추출\n",
        "        ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
        "        selected_sentences = [sentences[index] for _, index in ranked_sentences[:num_sentences]]\n",
        "        return ' '.join(selected_sentences)\n",
        "\n",
        "    # 문서 요약\n",
        "    summary = summarize(document, num_sentences=3)\n",
        "    print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61TjPTMrY13E",
        "outputId": "bf569c75-8f14-4377-9c6e-6a123ba25bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FACE WITH TEARS OF JOY\n"
          ]
        }
      ],
      "source": [
        "# 이모티콘\n",
        "import unicodedata\n",
        "print(unicodedata.name('😂'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUkmziedY13E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJu0W9llY13F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOGdd4sjY13F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "newprj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "37dcb171acb47c3d04f804a42efe3935da75a96b4220c54673b89fccb59f3177"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}