{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XSEKIkmY129"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXcCpxyPY12-"
      },
      "source": [
        "#### íƒ‘ë¦¬ë·°ì–´ df\n",
        "\n",
        "ì‘ì„±ì, ì£¼ë¬¸ ë‚ ì§œ, ë¦¬ë·° ì‘ì„± ë‚ ì§œ, ë¦¬ë·° ë‚´ìš©, ë¦¬ë·°ë‹¹ â€˜ë„ì›€ì´ ë¼ìš”â€™ ê°œìˆ˜, í•œë‹¬ ì´ìƒ ì‚¬ìš©, ì¬êµ¬ë§¤ ì—¬ë¶€, ì‚¬ì§„ ê°œìˆ˜, ì œí’ˆ êµ¬ë§¤ ë°©ë²•, ë¦¬ë·° ê³ ìœ ë²ˆí˜¸, í‰ì (ê¸ë¶€ì •)\n",
        "ë¦¬ë·° ì“´ ì£¼ê¸°, ë¦¬ë·° ê¸¸ì´, ì´ â€˜ë„ì›€ì´ ë¼ìš”â€™, ë¦¬ë·°ë‹¹ â€˜ë„ì›€ì´ ë¼ìš”â€™ (í‰ê· ), ì²´í—˜ë‹¨ ë¦¬ë·°ì™€ ì¼ë°˜ ë¦¬ë·° ì°¨ì´ (ë¦¬ë·° ê¸¸ì´ í¸ì°¨)\n",
        "\n",
        "- gdasSeq  :  ë¦¬ë·° ê³ ìœ ë²ˆí˜¸\n",
        "- gdasScrVal: í‰ì  (2,4,6,8,10)\n",
        "- dispRegDate : ë¦¬ë·° ì—…ë¡œë“œ ë‚ ì§œ\n",
        "- gdasCont : ë¦¬ë·° ë³¸ë¬¸\n",
        "- ordDate: ìƒí’ˆ ì£¼ë¬¸ ë‚ ì§œ\n",
        "- photoList: ì‚¬ì§„ ë¦¬ìŠ¤íŠ¸ (ì‚¬ì§„ ì—†ìœ¼ë©´ null)\n",
        "- recommCnt: ë„ì›€ì´ ë¼ìš” ê°œìˆ˜\n",
        "- renewUsed1mmGdasYn: í•œë‹¬ì´ìƒ ì‚¬ìš©\n",
        "- firstGdasYn: ì²« êµ¬ë§¤ ì—¬ë¶€ (ì¬êµ¬ë§¤ë©´ â€œNâ€ ì•„ë‹ˆë©´ â€œYâ€)\n",
        "- mbrNo: ë¦¬ë·°ë¥¼ ì‘ì„±í•œ íšŒì›ì˜ ê³ ìœ  ì‹ë³„ì\n",
        "- gdasSctCd : ì œí’ˆ êµ¬ë§¤ ë°©ë²• (10 - ì˜¨ë¼ì¸, 60 - ë§¤ì¥, 50 - ì²´í—˜ë‹¨, 70 - ì„ ë¬¼)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo4TiN7IY12_",
        "outputId": "fbf09601-ae6b-4f92-8881-dc9ed5b3de6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/mn/w592whfs2tb4g8s658288fb00000gn/T/ipykernel_9186/3744978623.py:3: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  top_df = pd.read_csv(topReviews_path, header=0, encoding='UTF-8')\n"
          ]
        }
      ],
      "source": [
        "# íƒ‘ë¦¬ë·°ì–´ ì •ë³´ DFë¡œ ê°€ì ¸ì˜¤ê¸°\n",
        "topReviews_path = '/Users/ryeongjoo/Desktop/workspace/semi_prj/topReviews.csv'\n",
        "top_df = pd.read_csv(topReviews_path, header=0, encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mids7AYdY12_"
      },
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ì¹¼ëŸ¼ë§Œ ë‹´ì€ DF\n",
        "my_top_df = top_df[['mbrNo','ordDate','dispRegDate','gdasCont','recommCnt','renewUsed1mmGdasYn','firstGdasYn', 'gdasSeq', 'gdasScrVal','gdasSctCd' ]]\n",
        "# print(my_top_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRtJ0VnNY13A"
      },
      "outputs": [],
      "source": [
        "# NaN ê°’ ë“œë\n",
        "my_top_df = my_top_df.dropna(subset=['gdasCont'])\n",
        "\n",
        "# ì˜ì–´ ì†Œë¬¸ì í†µì¼\n",
        "my_top_df['gdasCont'] = my_top_df['gdasCont'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuadh85EY13A"
      },
      "outputs": [],
      "source": [
        "# ì •ê·œì‹ì„ ì´ìš©í•˜ì—¬ ì´ëª¨í‹°ì½˜ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
        "def extract_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001f600-\\U0001f64f\"  # ì´ëª¨í‹°ì½˜\n",
        "        u\"\\U0001f300-\\U0001f5ff\"  # ê¸°í˜¸ ë° ë¬¸ì¥ ë¶€í˜¸\n",
        "        u\"\\U0001f680-\\U0001f6ff\"  # ê¸°íƒ€ ì´ëª¨í‹°ì½˜\n",
        "        u\"\\U0001f1e0-\\U0001f1ff\"  # êµ­ê¸° ë° ê¸°í˜¸\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.findall(text)\n",
        "\n",
        "# 'ì´ëª¨í‹°ì½˜' ì—´ ìƒì„±\n",
        "my_top_df['unicode'] = my_top_df['gdasCont'].apply(lambda x: extract_emoji(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSBLz1iSY13A"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·°ë‚´ìš© ì¤‘ë³µë¬¸ì, ì´ëª¨í‹°ì½˜ ì œê±°\n",
        "clean_reviews = []\n",
        "emoticon_list = []\n",
        "\n",
        "def remove_emoji(text):\n",
        "    # ì´ëª¨í‹°ì½˜ íŒ¨í„´ ì •ì˜\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # ì´ëª¨í‹°ì½˜\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # ì‹¬ë³¼\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # íŠ¸ëœìŠ¤í¬íŠ¸ ë° ì§€ë„\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # êµ­ê¸° ë° ì´ëª¨ì§€\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    # ì´ëª¨í‹°ì½˜ ì œê±°\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "for review in my_top_df['gdasCont'] :\n",
        "    \n",
        "    # ì´ˆì„±, ì¤„ë°”ê¿ˆ ì œê±°\n",
        "    review = re.sub('[ã„±-ã…ã…-ã…£]', '', review)\n",
        "    review = re.sub('[\\r\\n]', ' ', review)  \n",
        "    \n",
        "    # ì´ëª¨í‹°ì½˜ ì œê±°\n",
        "    review = remove_emoji(review)\n",
        "    \n",
        "    clean_reviews.append(review)\n",
        "    \n",
        "my_top_df['gdasCont'] = clean_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4OWHHWxY13A"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·° ê¸¸ì´ ì¹¼ëŸ¼ ì¶”ê°€\n",
        "my_top_df['cont_length'] = my_top_df['gdasCont'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# print(my_top_df.head())\n",
        "\n",
        "# ì´ëª¨í‹°ì½˜ ê°œìˆ˜ ì¹¼ëŸ¼ ì¶”ê°€\n",
        "my_top_df['emoCnt'] = my_top_df['unicode'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KotjTvQMY13A"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·° ì£¼ê¸° ì¹¼ëŸ¼\n",
        "# ë¦¬ë·° ì‘ì„± ë‚ ì§œ - êµ¬ë§¤ì¼ì\n",
        "\n",
        "# ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜\n",
        "my_top_df['dispRegDate'] = pd.to_datetime(my_top_df['dispRegDate'])\n",
        "my_top_df['ordDate'] = pd.to_datetime(my_top_df['ordDate'])\n",
        "\n",
        "# NaNì´ ì•„ë‹Œ í–‰ ì„ íƒ\n",
        "subset = my_top_df[my_top_df['ordDate'].notnull() ]\n",
        "\n",
        "# ë‘ ë‚ ì§œì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ ì¹¼ëŸ¼ì— ì¶”ê°€\n",
        "my_top_df.loc[subset.index, 'or_diff'] = my_top_df['dispRegDate'] - my_top_df['ordDate']\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "# print(my_top_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz6kRwZoY13A"
      },
      "outputs": [],
      "source": [
        "my_top_df['pn'] = [1 if x > 6 else 0 for x in my_top_df['gdasScrVal']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WC7MYAiY13A"
      },
      "source": [
        "#### ë¦¬ë·°ì–´ë³„ df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb9mYLfzY13B"
      },
      "outputs": [],
      "source": [
        "reviewer_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7UHZqxxY13B"
      },
      "outputs": [],
      "source": [
        "# mbrNo ì¹¼ëŸ¼ ìƒì„±\n",
        "unique_mbrNo = my_top_df['mbrNo'].unique()  # ì¤‘ë³µì„ ì œê±°í•œ mbrNo ê°’ ì¶”ì¶œ\n",
        "reviewer_df['mbrNo'] = pd.Series(unique_mbrNo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YdeS5lmY13B"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·°ì–´ë³„ í‰ê·  ë¦¬ë·° ê¸¸ì´\n",
        "# ì´ ë¦¬ë·° ê¸¸ì´ í‰ê·  ê³„ì‚°\n",
        "contlen_df = my_top_df.groupby('mbrNo')['cont_length'].mean().reset_index().rename(columns={'cont_length': 'contlen_mean'})\n",
        "\n",
        "# reviewer_dfì™€ contlen_df ì¡°ì¸\n",
        "reviewer_df = pd.merge(reviewer_df, contlen_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHf0wtLTY13B"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·°ì–´ë³„ ì´ ë„ì›€ì´ ë¼ìš” ê°œìˆ˜\n",
        "\n",
        "# ì´ ë¦¬ë·° ê°œìˆ˜ ê³„ì‚°\n",
        "recommSum_df = my_top_df.groupby('mbrNo')['recommCnt'].sum().reset_index().rename(columns={'recommCnt': 'total_recomm'})\n",
        "\n",
        "# reviewer_dfì™€ recommSum_df ì¡°ì¸\n",
        "reviewer_df = pd.merge(reviewer_df, recommSum_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm87xD-zY13B"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·°ì–´ë³„ ì‘ì„± ë¦¬ë·° ê°œìˆ˜\n",
        "reviewCnt_df = my_top_df.groupby('mbrNo')['gdasCont'].count().reset_index().rename(columns={'gdasCont': 'gdas_cnt'})\n",
        "reviewer_df = pd.merge(reviewer_df, reviewCnt_df, on='mbrNo', how='left')\n",
        "\n",
        "# ë¦¬ë·°ì–´ë³„ ë¦¬ë·° ê°œìˆ˜ë‹¹ í‰ê·  ë„ì›€ì´ ë¼ìš” ê°œìˆ˜\n",
        "reviewer_df['recomm_mean'] = reviewer_df['total_recomm'] / reviewer_df['gdas_cnt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRIQsPeDY13B"
      },
      "outputs": [],
      "source": [
        "# ë¦¬ë·°ì–´ë³„ ì²´í—˜ë‹¨ ë¦¬ë·°ì™€ ì¼ë°˜ ë¦¬ë·° ì°¨ì´ (ë¦¬ë·° ê¸¸ì´ í¸ì°¨)\n",
        "\n",
        "# ì²´í—˜ë‹¨ ë¦¬ë·°ê¸¸ì´ í‰ê· \n",
        "test_df = my_top_df.loc[my_top_df['gdasSctCd'] == 50].groupby('mbrNo')['cont_length'].mean()\n",
        "\n",
        "# ì²´í—˜ë‹¨ ì œì™¸í•œ ë¦¬ë·° ê¸¸ì´ í‰ê· \n",
        "buy_df = my_top_df.loc[my_top_df['gdasSctCd'] != 50].groupby('mbrNo')['cont_length'].mean()\n",
        "\n",
        "# ì²´í—˜ë‹¨ ë¦¬ë·°ê¸¸ì´ - ì²´í—˜ë‹¨ ì œì™¸í•œ ë¦¬ë·° ê¸¸ì´ \n",
        "diff_df = pd.DataFrame({'tb_len_diff': test_df - buy_df}).reset_index()\n",
        "\n",
        "# reviewer_dfì™€ recommSum_df ì¡°ì¸\n",
        "reviewer_df = pd.merge(reviewer_df, diff_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtSgOzFZY13C"
      },
      "outputs": [],
      "source": [
        "# í‰ê·  ì´ëª¨í‹°ì½˜ ê°œìˆ˜\n",
        "emoCntMean_df = my_top_df.groupby('mbrNo')['emoCnt'].mean().reset_index().rename(columns={'emoCnt': 'emoCntMean'})\n",
        "reviewer_df = pd.merge(reviewer_df, emoCntMean_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXY0gCqIY13C"
      },
      "outputs": [],
      "source": [
        "# í‰ì  ê¸ë¶€ì • ê²½í–¥\n",
        "scrPN_df = my_top_df.groupby('mbrNo')['pn'].mean().reset_index().rename(columns={'pn': 'scrPN'})\n",
        "reviewer_df = pd.merge(reviewer_df, scrPN_df, on='mbrNo', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhIK1Y7zY13C",
        "outputId": "a1331360-5e4e-4217-8329-905824b80862"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mbrNo</th>\n",
              "      <th>contlen_mean</th>\n",
              "      <th>total_recomm</th>\n",
              "      <th>gdas_cnt</th>\n",
              "      <th>recomm_mean</th>\n",
              "      <th>tb_len_diff</th>\n",
              "      <th>emoCntMean</th>\n",
              "      <th>topRvrRnk</th>\n",
              "      <th>topRvrRnk_group</th>\n",
              "      <th>scrPN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M0000004535694</td>\n",
              "      <td>83.013333</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>300</td>\n",
              "      <td>3.393333</td>\n",
              "      <td>218.630508</td>\n",
              "      <td>0.343333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M0000012163234</td>\n",
              "      <td>101.200000</td>\n",
              "      <td>1216.0</td>\n",
              "      <td>80</td>\n",
              "      <td>15.200000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M0000016082816</td>\n",
              "      <td>110.190909</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>110</td>\n",
              "      <td>10.700000</td>\n",
              "      <td>222.396226</td>\n",
              "      <td>0.009091</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.945455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M0000003453847</td>\n",
              "      <td>73.930000</td>\n",
              "      <td>604.0</td>\n",
              "      <td>100</td>\n",
              "      <td>6.040000</td>\n",
              "      <td>248.250000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M0000010425691</td>\n",
              "      <td>505.030000</td>\n",
              "      <td>765.0</td>\n",
              "      <td>100</td>\n",
              "      <td>7.650000</td>\n",
              "      <td>37.208333</td>\n",
              "      <td>1.560000</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            mbrNo  contlen_mean  total_recomm  gdas_cnt  recomm_mean  \\\n",
              "0  M0000004535694     83.013333        1018.0       300     3.393333   \n",
              "1  M0000012163234    101.200000        1216.0        80    15.200000   \n",
              "2  M0000016082816    110.190909        1177.0       110    10.700000   \n",
              "3  M0000003453847     73.930000         604.0       100     6.040000   \n",
              "4  M0000010425691    505.030000         765.0       100     7.650000   \n",
              "\n",
              "   tb_len_diff  emoCntMean  topRvrRnk topRvrRnk_group     scrPN  \n",
              "0   218.630508    0.343333          1               1  1.000000  \n",
              "1   304.000000    0.250000          2               1  0.850000  \n",
              "2   222.396226    0.009091          3               1  0.945455  \n",
              "3   248.250000    0.450000          4               1  0.990000  \n",
              "4    37.208333    1.560000          5               1  0.960000  "
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviewer_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kqD4NKDY13C"
      },
      "source": [
        "#### ìƒ,ì¤‘,í•˜ìœ„ ë¦¬ë·°ì–´ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWj6IyDLY13C",
        "outputId": "27e76c0f-8169-4f6e-eaf5-594d58aa6b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-27.177575757575752\n",
            "83.01333333333334 101.2 110.19090909090909\n"
          ]
        }
      ],
      "source": [
        "# íƒ‘ë¦¬ë·°ì–´(1~1000) ìƒìœ„,ì¤‘ìœ„,í•˜ìœ„ë¡œ ë‚˜ëˆ ì„œ ë¦¬ë·°ê¸¸ì´ì°¨ì´ (í¸ì°¨) êµ¬í•˜ê¸°\n",
        "\n",
        "reviewer_df['topRvrRnk'] = reviewer_df['mbrNo'].index+1\n",
        "\n",
        "#íƒ‘ë¦¬ë·°ì–´(1~2000) ìƒìœ„,ì¤‘ìœ„,í•˜ìœ„ë¡œ ë‚˜ëˆˆ ì¹¼ëŸ¼ ì¶”ê°€\n",
        "reviewer_df['topRvrRnk_group'] = pd.cut(reviewer_df['topRvrRnk'], bins=[0, 657, 1315, 1972], labels=[1, 2, 3])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7h2_zolY13C",
        "outputId": "83f535b1-7776-4afa-fa28-7b16d8350ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "190.0\n",
            "300.0 80.0 110.0\n"
          ]
        }
      ],
      "source": [
        "# ìƒìœ„ ë¦¬ë·°ì–´ì™€ í•˜ìœ„ ë¦¬ë·°ì–´ í‰ê·  ì‘ì„± ë¦¬ë·° ê°œìˆ˜ ì°¨ì´ \n",
        "high_review_cnt = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['gdas_cnt'].mean()\n",
        "middle_review_cnt = reviewer_df.loc[reviewer_df['topRvrRnk'] == 2]['gdas_cnt'].mean()\n",
        "low_review_cnt = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['gdas_cnt'].mean()\n",
        "\n",
        "diff_review_cnt = high_review_cnt - low_review_cnt\n",
        "print(diff_review_cnt)\n",
        "print(high_review_cnt, middle_review_cnt, low_review_cnt)\n",
        "\n",
        "# ìƒìœ„ ë¦¬ë·°ì–´ë“¤ì˜ í‰ê·  ë¦¬ë·° ê°œìˆ˜ê°€ í›¨ì”¬ ë§ìŒì„ ì•Œ ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XkoCro4Y13C"
      },
      "outputs": [],
      "source": [
        "#ìƒìœ„ ë¦¬ë·°ì–´ì™€ í•˜ìœ„ ë¦¬ë·°ì–´ ì°¨ì´ (ë¦¬ë·° ê¸¸ì´ í¸ì°¨)\n",
        "high_review_length = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['contlen_mean'].mean()\n",
        "middle_review_length = reviewer_df.loc[reviewer_df['topRvrRnk'] == 2]['contlen_mean'].mean()\n",
        "low_review_length = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['contlen_mean'].mean()\n",
        "\n",
        "diff_review_length = high_review_length - low_review_length\n",
        "print(diff_review_length)\n",
        "print(high_review_length, middle_review_length, low_review_length)\n",
        "\n",
        "# ì˜¤íˆë ¤ í•˜ìœ„ íƒ‘ë¦¬ë·°ì–´ë“¤ì˜ í‰ê·  ë¦¬ë·° ê¸¸ì´ê°€ ë” ê¸¸ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHoPXgR-Y13D",
        "outputId": "602c8781-7f59-47b3-f2b6-a8d13f1cce09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.33424242424242423\n"
          ]
        }
      ],
      "source": [
        "#ìƒìœ„ ë¦¬ë·°ì–´ì™€ í•˜ìœ„ ë¦¬ë·°ì–´ ì´ëª¨í‹°ì½˜ ê°œìˆ˜ ì°¨ì´\n",
        "high_review_emo = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['emoCntMean'].mean()\n",
        "low_review_emo = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['emoCntMean'].mean()\n",
        "\n",
        "diff_review_emo = high_review_emo - low_review_emo\n",
        "print(diff_review_emo)\n",
        "\n",
        "# ìƒìœ„ íƒ‘ë¦¬ë·°ì–´ë“¤ì˜ í‰ê·  ì´ëª¨í‹°ì½˜ ê°œìˆ˜ê°€ ë” ë§ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqshe7xkY13D",
        "outputId": "a614b52d-e92a-447f-c95a-a4583b5d5646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.054545454545454564\n"
          ]
        }
      ],
      "source": [
        "# ìƒìœ„ ë¦¬ë·°ì–´ì™€ í•˜ìœ„ ë¦¬ë·°ì–´ í‰ì  ê¸ë¶€ì • ì°¨ì´ \n",
        "high_review_pn = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['scrPN'].mean()\n",
        "low_review_pn = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['scrPN'].mean()\n",
        "\n",
        "diff_review_pn = high_review_pn - low_review_pn\n",
        "print(diff_review_pn)\n",
        "\n",
        "# ìƒìœ„ íƒ‘ë¦¬ë·°ì–´ë“¤ì´ í‰ê· ì ìœ¼ë¡œ ë” ë†’ì€ í‰ì ì„ ì£¼ì—ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g2fOmrLY13D",
        "outputId": "79ffa49c-b968-4b7f-d3a5-659e80b41dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-7.306666666666666\n",
            "3.3933333333333335 15.2 10.7\n"
          ]
        }
      ],
      "source": [
        "# ìƒìœ„ ë¦¬ë·°ì–´ì™€ í•˜ìœ„ ë¦¬ë·°ì–´ í‰ê·  ë„ì›€ì´ë¼ìš” ì°¨ì´ \n",
        "high_review_rcm = reviewer_df.loc[reviewer_df['topRvrRnk'] == 1]['recomm_mean'].mean()\n",
        "middle_review_rcm = reviewer_df.loc[reviewer_df['topRvrRnk'] == 2]['recomm_mean'].mean()\n",
        "low_review_rcm = reviewer_df.loc[reviewer_df['topRvrRnk'] == 3]['recomm_mean'].mean()\n",
        "\n",
        "diff_review_rcm = high_review_rcm - low_review_rcm\n",
        "print(diff_review_rcm)\n",
        "print(high_review_rcm, middle_review_rcm, low_review_rcm)\n",
        "\n",
        "# í•˜ìœ„ ë¦¬ë·°ì–´ë“¤ì˜ í‰ê·  ë„ì›€ì´ë¼ìš” ê°œìˆ˜ê°€ ë” ë§ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O81g3z-aY13D"
      },
      "outputs": [],
      "source": [
        "# def text_len(text):\n",
        "#     return re.sub('[^ã…-ã…£ê°€-í£ .,+â€¦\\';:\\-ã†\\(\\)&0-9A-Za-z]+', '', text)\n",
        "# my_top_df['gdasCont'][:10].apply(text_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlZad26RY13D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wsbfXyuY13D"
      },
      "source": [
        "#### ë¦¬ë·° ë‚´ìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxfRnWybY13D",
        "outputId": "1b9e7575-5d13-4587-a451-30edfc5e6ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ì œ', 'ìµœê·¼', 'ì˜¬ë¦¬ë¸Œì˜', 'ê°€ì¥', 'ë§ì´', 'êµ¬ë§¤', 'í–ˆë˜', 'ì œí’ˆ', 'ì¤‘', 'í•˜ë‚˜', 'ì…ë‹ˆë‹¤', 'ì‹ ë‘', '30', 'g', 'ì§œ', 'ë¦¬', 'í•˜ë£¨', 'ë‘', 'ë´‰ì§€', 'ì”©', 'ë¨¹ë„¤ìš”', 'í•˜ì§€ë§Œ', 'ì œì…', 'ë§ì´', 'ë‹¬ì•„ìš”'], ['í—ˆë¸Œ', 'ì íŠ¸', 'ë¯¹ìŠ¤ë„›', 'ê²¬ê³¼ë¥˜', 'êµ¬ì„±ì€', 'ë§˜', 'ë“œëŠ”ë°', 'ë„˜', 'ì§œìš”', 'ê·¸ë˜ë„', '1', '1', 'í–‰ì‚¬', 'í•˜ê¸¸ë˜', 'êµ¬ë§¤', 'í–ˆëŠ”ë°', 'ê²‰', 'ë¬»ì€', 'ê°€ë£¨', 'í„¸ì–´ë‚´ê³ ', 'ë¨¹ì–´ì•¼', 'í•´'], ['ì•„ì¹¨', 'ì£¼ë¡œ', 'ë§ˆì‹œê³ ', 'ìˆëŠ”', 'ì‚¬ê³¼', 'ë‹¹ê·¼', 'ë§›', 'ì´', 'ë„ˆ', 'ì£¼ìŠ¤', 'ì…ë‹ˆë‹¤', 'ì œ', '5ë…„', 'ì„', 'ë„˜ê²Œ', 'ë§ˆì‹œê³ ', 'ìˆëŠ”ë°', 'ê¾¸ì¤€í•˜ê²Œ', 'ë§ˆì‹œë©´', 'í™”ì¥ì‹¤', 'ê°€ëŠ”ê²Œ', 'í¸í•´ì ¸ì„œ', 'ì¢‹ì•„ìš”'], ['ì‹ ë‘', 'ì¤„ë ¤ê³ ', 'ì‹ ì²­', 'í–ˆì–´ìš”', 'ë‹¤ë¹„ë„í”„', 'í–¥ìˆ˜', 'í”„ë‘ìŠ¤', 'ë§Œë“¤ì–´', 'ì¡Œê³ ', 'í–¥ìˆ˜ë³‘', 'ë„¤ëª¨', 'í˜•íƒœ', 'ë˜ì–´ìˆê³ ', 'ì¡ê¸°', 'í¸í•˜ë„¤ìš”', 'ì œí’ˆ', 'ë°›ê³ ', 'ë°”ë¡œ', 'ì‹ ë‘', 'ë¿Œë ¤', 'ë´¤ëŠ”ë°', 'í–¥', 'ë”±', 'ë‚¨ì', 'ë“¤', 'ì¢‹ì•„í• ë§Œ', 'í•œ', 'í–¥', 'ìš”', 'ì¼ë‹¨', 'í–¥', 'ì¤‘ìš”í•˜ì§€ë§Œ', 'ì§€ì†', 'ë ¥', 'ì¢‹ì•„ì•¼', 'í•´ì„œ', 'ì‹ ë‘', 'ë¿Œë¦¬', 'í•œë‘', 'ì‹œê°„', 'ì§€ë‚˜ì„œë„', 'í–¥', 'ë‚˜ëŠ”ì§€', 'ì˜†', 'ê°€ë´¤ë”ë‹ˆ', 'ì§„í•˜ê²ŒëŠ”', 'ì•„ë‹ˆì§€ë§Œ', 'ì€ì€í•˜ê²Œ', 'ì”í–¥', 'ë‚¨ì•„', 'ìˆëŠ”ë“¯', 'í•˜ë„¤ìš”', 'ë‚ ì”¨', 'ì ì ', 'ë”ì›Œì§€ëŠ”ë°', 'ì—¬ë¦„', 'ë¿Œë ¤ë„', 'ì¢‹ì„ê²ƒ', 'ê°™ë‹¤ëŠ”', 'ìƒê°', 'ë“œë„¤', 'ë‚˜ì´', 'ìƒê´€ì—†ì´', 'ëª¨ë“ ', 'ì—°ë ¹', 'ì¸µ', 'ì‚¬ìš©', 'í•˜ê¸°ì—', 'ê´œì°®ì€', 'ì œí’ˆ', 'ë“¯', 'í•©ë‹ˆë‹¤'], ['íŒ½ì´ë²„ì„¯', 'ìœ ì‚°ê· ', 'ë°œíš¨', 'ì•¡', 'ë“¤ì–´ê°€ì„œ', 'ê¾¸ì¤€í•˜ê²Œ', 'ë§ˆì‹œë©´', 'í™”ì¥ì‹¤', 'ê°€ëŠ”ê²Œ', 'í¸í•´ì§€ë„¤ìš”']]\n"
          ]
        }
      ],
      "source": [
        "# í† í°í™”\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "tokens_results = []\n",
        "\n",
        "for text in my_top_df['gdasCont'].head(5):\n",
        "    \n",
        "    # Okt ê°ì²´ ìƒì„±\n",
        "    okt = Okt()\n",
        "\n",
        "    # ì´ˆì„±, ì¤„ë°”ê¿ˆ ì œê±°\n",
        "    text = re.sub('[ã„±-ã…ã…-ã…£\\r\\n]', '', text)\n",
        "\n",
        "    tokens = okt.pos(text)\n",
        "    result = []\n",
        "\n",
        "    for word, tag in tokens:\n",
        "        if tag not in ['Josa', 'Eomi', 'Punctuation']:\n",
        "            result.append(word)\n",
        "\n",
        "    tokens_results.append(result)\n",
        "    \n",
        "print(tokens_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZKepz33Y13D",
        "outputId": "64c95f1a-c614-496e-849c-b2eb19919bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['30' 'ê°€ì¥' 'êµ¬ë§¤' 'ë‹¬ì•„ìš”' 'ë§ì´' 'ë¨¹ë„¤ìš”' 'ë´‰ì§€' 'ì‹ ë‘' 'ì˜¬ë¦¬ë¸Œì˜' 'ì…ë‹ˆë‹¤' 'ì œì…' 'ì œí’ˆ' 'ìµœê·¼'\n",
            " 'í•˜ë‚˜' 'í•˜ë£¨' 'í•˜ì§€ë§Œ' 'í–ˆë˜']\n",
            "['ê°€ë£¨' 'ê²¬ê³¼ë¥˜' 'êµ¬ë§¤' 'êµ¬ì„±ì€' 'ê·¸ë˜ë„' 'ë“œëŠ”ë°' 'ë¨¹ì–´ì•¼' 'ë¬»ì€' 'ë¯¹ìŠ¤ë„›' 'ì íŠ¸' 'ì§œìš”' 'í„¸ì–´ë‚´ê³ ' 'í•˜ê¸¸ë˜'\n",
            " 'í–ˆëŠ”ë°' 'í–‰ì‚¬' 'í—ˆë¸Œ']\n",
            "['5ë…„' 'ê°€ëŠ”ê²Œ' 'ê¾¸ì¤€í•˜ê²Œ' 'ë„˜ê²Œ' 'ë‹¹ê·¼' 'ë§ˆì‹œê³ ' 'ë§ˆì‹œë©´' 'ì‚¬ê³¼' 'ì•„ì¹¨' 'ì…ë‹ˆë‹¤' 'ìˆëŠ”' 'ìˆëŠ”ë°' 'ì¢‹ì•„ìš”'\n",
            " 'ì£¼ë¡œ' 'ì£¼ìŠ¤' 'í¸í•´ì ¸ì„œ' 'í™”ì¥ì‹¤']\n",
            "['ê°€ë´¤ë”ë‹ˆ' 'ê°™ë‹¤ëŠ”' 'ê´œì°®ì€' 'ë‚˜ëŠ”ì§€' 'ë‚˜ì´' 'ë‚ ì”¨' 'ë‚¨ì•„' 'ë‚¨ì' 'ë„¤ëª¨' 'ë‹¤ë¹„ë„í”„' 'ë”ì›Œì§€ëŠ”ë°' 'ë˜ì–´ìˆê³ '\n",
            " 'ë“œë„¤' 'ë§Œë“¤ì–´' 'ëª¨ë“ ' 'ë°”ë¡œ' 'ë°›ê³ ' 'ë´¤ëŠ”ë°' 'ë¿Œë ¤' 'ë¿Œë ¤ë„' 'ë¿Œë¦¬' 'ì‚¬ìš©' 'ìƒê´€ì—†ì´' 'ìƒê°' 'ì‹œê°„'\n",
            " 'ì‹ ë‘' 'ì‹ ì²­' 'ì•„ë‹ˆì§€ë§Œ' 'ì—¬ë¦„' 'ì—°ë ¹' 'ì€ì€í•˜ê²Œ' 'ì¼ë‹¨' 'ìˆëŠ”ë“¯' 'ì”í–¥' 'ì¡ê¸°' 'ì ì ' 'ì œí’ˆ' 'ì¡Œê³ '\n",
            " 'ì¢‹ì•„ì•¼' 'ì¢‹ì•„í• ë§Œ' 'ì¢‹ì„ê²ƒ' 'ì¤„ë ¤ê³ ' 'ì¤‘ìš”í•˜ì§€ë§Œ' 'ì§€ë‚˜ì„œë„' 'ì§€ì†' 'ì§„í•˜ê²ŒëŠ”' 'í¸í•˜ë„¤ìš”' 'í”„ë‘ìŠ¤' 'í•˜ê¸°ì—'\n",
            " 'í•˜ë„¤ìš”' 'í•œë‘' 'í•©ë‹ˆë‹¤' 'í•´ì„œ' 'í–ˆì–´ìš”' 'í–¥ìˆ˜' 'í–¥ìˆ˜ë³‘' 'í˜•íƒœ']\n",
            "['ê°€ëŠ”ê²Œ' 'ê¾¸ì¤€í•˜ê²Œ' 'ë“¤ì–´ê°€ì„œ' 'ë§ˆì‹œë©´' 'ë°œíš¨' 'ìœ ì‚°ê· ' 'íŒ½ì´ë²„ì„¯' 'í¸í•´ì§€ë„¤ìš”' 'í™”ì¥ì‹¤']\n"
          ]
        }
      ],
      "source": [
        "# í‚¤ì›Œë“œ ì¶”ì¶œ\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "for documents in tokens_results:\n",
        "\n",
        "    # TfidfVectorizer ê°ì²´ ìƒì„±\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # TfidfVectorizerë¡œ ë¬¸ì„œ ë²¡í„°í™” ìˆ˜í–‰\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "    # get_feature_names() ë©”ì„œë“œë¥¼ ì´ìš©í•´ ë‹¨ì–´ ëª©ë¡ê³¼ ê° ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ í™•ì¸\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjnhCHjpY13E",
        "outputId": "2e12770e-6bc6-4eb3-c1f8-ce9414f4a16d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Kss]: Oh! You have konlpy.tag.Mecab in your environment. Kss will take this as a backend! :D\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í•˜ì§€ë§Œ ì œì…ì—” ë§ì´ ë‹¬ì•„ìš” ì‹ ë‘ì´ 30gì§œë¦¬ë¥¼ í•˜ë£¨ì— ë‘ë´‰ì§€ì”©  ë¨¹ë„¤ìš” ì œê°€ ìµœê·¼ì— ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ê°€ì¥ ë§ì´  êµ¬ë§¤ë¥¼ í–ˆë˜ ì œí’ˆì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤\n",
            "ê·¸ë˜ë„ 1+1 í–‰ì‚¬ë¥¼ í•˜ê¸¸ë˜ êµ¬ë§¤ë¥¼  í–ˆëŠ”ë° ê²‰ì— ë¬»ì€ ê°€ë£¨ë¥¼ í„¸ì–´ë‚´ê³   ë¨¹ì–´ì•¼ í•´ìš” í—ˆë¸Œì íŠ¸ ë¯¹ìŠ¤ë„›ì€ ê²¬ê³¼ë¥˜êµ¬ì„±ì€  ë§˜ì— ë“œëŠ”ë° ë„˜ì§œìš”\n",
            "ì œê°€ 5ë…„ì„ ë„˜ê²Œ ë§ˆì‹œê³  ìˆëŠ”ë° ê¾¸ì¤€í•˜ê²Œ  ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ í¸í•´ì ¸ì„œ ì¢‹ì•„ìš” ì•„ì¹¨ì— ì£¼ë¡œ ë§ˆì‹œê³  ìˆëŠ” ì‚¬ê³¼ë‹¹ê·¼ë§›  ì´ë„ˆì£¼ìŠ¤ì…ë‹ˆë‹¤\n",
            "ì‹ ë‘ì„ ì¤„ë ¤ê³  ì‹ ì²­ì„ í–ˆì–´ìš”~ ì¼ë‹¨ í–¥ë„ ì¤‘ìš”í•˜ì§€ë§Œ ì§€ì†ë ¥ë„ ì¢‹ì•„ì•¼  í•´ì„œ ì‹ ë‘ì´ ë¿Œë¦¬ê³  í•œë‘ì‹œê°„ ì§€ë‚˜ì„œë„  í–¥ì´ ë‚˜ëŠ”ì§€ ì˜†ì— ê°€ë´¤ë”ë‹ˆ ì§„í•˜ê²ŒëŠ”  ì•„ë‹ˆì§€ë§Œ ì€ì€í•˜ê²Œ ì”í–¥ì´ ë‚¨ì•„ ìˆëŠ”ë“¯  í•˜ë„¤ìš” ë‚˜ì´ì™€ ìƒê´€ì—†ì´ ëª¨ë“  ì—°ë ¹ì¸µì´ ì‚¬ìš©í•˜ê¸°ì—  ê´œì°®ì€ ì œí’ˆì¸ë“¯ í•©ë‹ˆë‹¤\n",
            "íŒ½ì´ë²„ì„¯ ìœ ì‚°ê·  ë°œíš¨ì•¡ì´ ë“¤ì–´ê°€ì„œ  ê¾¸ì¤€í•˜ê²Œ ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ  í¸í•´ì§€ë„¤ìš”\n"
          ]
        }
      ],
      "source": [
        "# ìš”ì•½\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Komoran\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import kss\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "for document in my_top_df['gdasCont'].head(5):\n",
        "    # Okt ê°ì²´ ìƒì„±\n",
        "    okt = Okt()\n",
        "\n",
        "    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\n",
        "    sentences = kss.split_sentences(document)\n",
        "\n",
        "    # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "    words_list = []\n",
        "    for sentence in sentences:\n",
        "        words = okt.pos(sentence, stem=True)\n",
        "        words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "        words_list.append(' '.join(words))\n",
        "\n",
        "    # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform(words_list)\n",
        "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "    # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
        "    def summarize(document, num_sentences=3):\n",
        "\n",
        "\n",
        "        # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "        words_list = []\n",
        "        for sentence in sentences:\n",
        "            words = okt.pos(sentence, stem=True)\n",
        "            words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "            words_list.append(' '.join(words))\n",
        "\n",
        "        # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf = vectorizer.fit_transform(words_list)\n",
        "        similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "        # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
        "        similarity_graph = similarity_matrix\n",
        "        nx_graph = nx.from_numpy_array(similarity_graph)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "\n",
        "        # í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ\n",
        "        ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
        "        selected_sentences = [sentences[index] for _, index in ranked_sentences[:num_sentences]]\n",
        "        return ' '.join(selected_sentences)\n",
        "\n",
        "    # ë¬¸ì„œ ìš”ì•½\n",
        "    summary = summarize(document, num_sentences=3)\n",
        "    print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPWc4_o9Y13E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g85FFJcXY13E",
        "outputId": "d54a8922-8bfd-4c4a-c466-bdfb14bd6a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í•˜ì§€ë§Œ ì œì…ì—” ë§ì´ ë‹¬ì•„ìš” ì‹ ë‘ì´ 30gì§œë¦¬ë¥¼ í•˜ë£¨ì— ë‘ë´‰ì§€ì”©  ë¨¹ë„¤ìš” ì œê°€ ìµœê·¼ì— ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ê°€ì¥ ë§ì´  êµ¬ë§¤ë¥¼ í–ˆë˜ ì œí’ˆì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤\n",
            "ê·¸ë˜ë„ 1+1 í–‰ì‚¬ë¥¼ í•˜ê¸¸ë˜ êµ¬ë§¤ë¥¼  í–ˆëŠ”ë° ê²‰ì— ë¬»ì€ ê°€ë£¨ë¥¼ í„¸ì–´ë‚´ê³   ë¨¹ì–´ì•¼ í•´ìš” í—ˆë¸Œì íŠ¸ ë¯¹ìŠ¤ë„›ì€ ê²¬ê³¼ë¥˜êµ¬ì„±ì€  ë§˜ì— ë“œëŠ”ë° ë„˜ì§œìš”\n",
            "ì œê°€ 5ë…„ì„ ë„˜ê²Œ ë§ˆì‹œê³  ìˆëŠ”ë° ê¾¸ì¤€í•˜ê²Œ  ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ í¸í•´ì ¸ì„œ ì¢‹ì•„ìš” ì•„ì¹¨ì— ì£¼ë¡œ ë§ˆì‹œê³  ìˆëŠ” ì‚¬ê³¼ë‹¹ê·¼ë§›  ì´ë„ˆì£¼ìŠ¤ì…ë‹ˆë‹¤\n",
            "ì‹ ë‘ì„ ì¤„ë ¤ê³  ì‹ ì²­ì„ í–ˆì–´ìš”~ ì¼ë‹¨ í–¥ë„ ì¤‘ìš”í•˜ì§€ë§Œ ì§€ì†ë ¥ë„ ì¢‹ì•„ì•¼  í•´ì„œ ì‹ ë‘ì´ ë¿Œë¦¬ê³  í•œë‘ì‹œê°„ ì§€ë‚˜ì„œë„  í–¥ì´ ë‚˜ëŠ”ì§€ ì˜†ì— ê°€ë´¤ë”ë‹ˆ ì§„í•˜ê²ŒëŠ”  ì•„ë‹ˆì§€ë§Œ ì€ì€í•˜ê²Œ ì”í–¥ì´ ë‚¨ì•„ ìˆëŠ”ë“¯  í•˜ë„¤ìš” ë‚˜ì´ì™€ ìƒê´€ì—†ì´ ëª¨ë“  ì—°ë ¹ì¸µì´ ì‚¬ìš©í•˜ê¸°ì—  ê´œì°®ì€ ì œí’ˆì¸ë“¯ í•©ë‹ˆë‹¤\n",
            "íŒ½ì´ë²„ì„¯ ìœ ì‚°ê·  ë°œíš¨ì•¡ì´ ë“¤ì–´ê°€ì„œ  ê¾¸ì¤€í•˜ê²Œ ë§ˆì‹œë©´ í™”ì¥ì‹¤ ê°€ëŠ”ê²Œ  í¸í•´ì§€ë„¤ìš”\n"
          ]
        }
      ],
      "source": [
        "# ìš”ì•½2\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Komoran\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import kss\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "for document in my_top_df['gdasCont'].head(5):\n",
        "    # Okt ê°ì²´ ìƒì„±\n",
        "    okt = Okt()\n",
        "    \n",
        "    # ì´ˆì„±, ì¤„ë°”ê¿ˆ ì œê±°\n",
        "    document = re.sub('[ã„±-ã…ã…-ã…£]', '', document)\n",
        "    document = re.sub('[\\r\\n]', ' ', document)\n",
        "    \n",
        "    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\n",
        "    sentences = kss.split_sentences(document)\n",
        "    \n",
        "    # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "    words_list = []\n",
        "    for sentence in sentences:\n",
        "        words = okt.pos(sentence, stem=True)\n",
        "        words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "        words_list.append(' '.join(words))\n",
        "\n",
        "    # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform(words_list)\n",
        "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "    # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
        "    def summarize(document, num_sentences=3):\n",
        "\n",
        "\n",
        "        # ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "        words_list = []\n",
        "        for sentence in sentences:\n",
        "            words = okt.pos(sentence, stem=True)\n",
        "            words = [word[0] for word in words if word[1] in ['Noun', 'Adjective', 'Verb']]\n",
        "            words_list.append(' '.join(words))\n",
        "\n",
        "        # TF-IDFë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf = vectorizer.fit_transform(words_list)\n",
        "        similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "        # TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½\n",
        "        similarity_graph = similarity_matrix\n",
        "        nx_graph = nx.from_numpy_array(similarity_graph)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "\n",
        "        # í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ\n",
        "        ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
        "        selected_sentences = [sentences[index] for _, index in ranked_sentences[:num_sentences]]\n",
        "        return ' '.join(selected_sentences)\n",
        "\n",
        "    # ë¬¸ì„œ ìš”ì•½\n",
        "    summary = summarize(document, num_sentences=3)\n",
        "    print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61TjPTMrY13E",
        "outputId": "bf569c75-8f14-4377-9c6e-6a123ba25bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FACE WITH TEARS OF JOY\n"
          ]
        }
      ],
      "source": [
        "# ì´ëª¨í‹°ì½˜\n",
        "import unicodedata\n",
        "print(unicodedata.name('ğŸ˜‚'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUkmziedY13E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJu0W9llY13F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOGdd4sjY13F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "newprj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "37dcb171acb47c3d04f804a42efe3935da75a96b4220c54673b89fccb59f3177"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}